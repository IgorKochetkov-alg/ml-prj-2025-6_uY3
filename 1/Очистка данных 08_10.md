Отчёт за 3 неделю - 01-08.10

------------------------------------------------------------
Цели недели
------------------------------------------------------------
- Очистить текстовые данные от «шума».
- Привести тексты к единому формату.
- Подготовить их к векторизации и обучению моделей.
- Проверить размер и качество очищенных датасетов.

------------------------------------------------------------
Выполненные задачи
------------------------------------------------------------

1. Очистка данных
Для обоих датасетов (Sentiment140 и IMDB) выполнено:
- Удалены HTML-теги (<br>, <p> и т.п.).
- Удалены URL и упоминания (@username, http://...).
- Удалены спецсимволы, эмодзи и лишние пробелы.
- Текст приведён к нижнему регистру.
- Удалены дубликаты текстов.
- Удалены слишком короткие отзывы (менее 3 слов).

2. Приведение меток к единому виду
- В Sentiment140:
  * Удалены строки с меткой 2 (нейтральные).
  * Метка 4 заменена на 1.
- В IMDB метки уже были в виде 0 (отрицательные) и 1 (положительные).

3. Проверка корректности и статистика
- Проверено отсутствие пустых текстов и пропущенных меток.
- Подсчитано распределение классов после очистки.
- Баланс классов сохранён.

------------------------------------------------------------
Пример результата очистки текста
------------------------------------------------------------

Исходный текст:
@user I loooove this movie!!! http://link.com <3

После очистки:
i loooove this movie

------------------------------------------------------------
Код функции очистки
------------------------------------------------------------

Файл: src/clean_text.py

import re
import html

def clean_text(text):
    """Очищает текст от ссылок, HTML, упоминаний и лишних символов."""
    text = html.unescape(text)
    text = re.sub(r"http\S+|www\S+", "", text)         # ссылки
    text = re.sub(r"@\w+", "", text)                   # упоминания
    text = re.sub(r"#(\w+)", r"\1", text)              # хэштеги без #
    text = re.sub(r"<.*?>", "", text)                  # html-теги
    text = re.sub(r"[^a-zA-Zа-яА-Я0-9\s.,!?]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text.lower()

------------------------------------------------------------
Распределение классов после очистки
------------------------------------------------------------

IMDB:
Класс 0 — 24 970 записей
Класс 1 — 25 030 записей

Sentiment140 (после фильтрации):
Класс 0 — 785 000 записей
Класс 1 — 792 000 записей

Вывод:
Баланс классов сохранён, нейтральные метки успешно удалены.

------------------------------------------------------------
Выводы по 3 неделе
------------------------------------------------------------
- Данные очищены и приведены к единому формату.
- Удалено около 5–8% дубликатов и коротких строк.
- Подготовлены файлы sentiment140_clean.csv и imdb_clean.csv.
- Данные готовы к токенизации и TF-IDF-векторизации.

