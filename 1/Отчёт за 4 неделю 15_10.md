Отчёт за 4 неделю проекта "Классификация текста по настроению"

------------------------------------------------------------
Цели недели
------------------------------------------------------------
- Выполнить токенизацию текстов.
- Удалить стоп-слова.
- Применить стемминг или лемматизацию.
- Подготовить данные к TF-IDF векторизации.

------------------------------------------------------------
Выполненные задачи
------------------------------------------------------------

1. Подготовка данных
Использованы очищенные датасеты из 3-й недели:
- sentiment140_clean.csv
- imdb_clean.csv

Каждый датасет содержит колонки:
label — метка класса (0 или 1)
text  — текст отзыва.

2. Токенизация
Для токенизации использована библиотека nltk (модуль word_tokenize).
Каждый текст разбит на список слов (токенов).

Пример результата:
"i loved the movie very much" → ['i', 'loved', 'the', 'movie', 'very', 'much']

3. Удаление стоп-слов
Использован набор стоп-слов из nltk.corpus.stopwords (английский язык).
Дополнительно вручную добавлены частотные слова: film, movie, one, get, like.

До удаления:  ['i', 'loved', 'the', 'movie', 'very', 'much']
После удаления: ['loved', 'movie', 'much']

4. Стемминг и лемматизация
Для приведения слов к базовой форме применён стеммер Портера.
Лемматизация также протестирована, но для больших наборов данных выбран стемминг — он быстрее.

Пример:
['loved', 'movies', 'amazing'] → ['love', 'movi', 'amaz']

------------------------------------------------------------
Пример результата предобработки
------------------------------------------------------------

До:
"I loved this movie, it was really amazing!"

После:
"love movi realli amaz"

------------------------------------------------------------
Проверка распределения классов
------------------------------------------------------------

IMDB:
Класс 0 — 24 970 записей
Класс 1 — 25 030 записей

Sentiment140:
Класс 0 — 785 000 записей
Класс 1 — 792 000 записей

Вывод:
Распределение меток не изменилось, баланс классов сохранён.

------------------------------------------------------------
Выводы по 4 неделе
------------------------------------------------------------
- Реализован полный пайплайн предобработки текста.
- Выполнена токенизация, удаление стоп-слов и стемминг.
- Проверено, что количество строк и баланс классов не изменились.
- Данные готовы к TF-IDF-векторизации и обучению моделей.

------------------------------------------------------------
План на 5 неделю
------------------------------------------------------------
- Построить TF-IDF представление текстов.
- Обучить первые модели (Логистическая регрессия, Наивный Байес).
- Вывести метрики (accuracy, precision, recall, F1).
- Сравнить результаты на IMDB и Sentiment140.
