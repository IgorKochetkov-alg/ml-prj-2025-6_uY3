# Отчет к 2025-10-29

- Подобран оптимизатор (SGD), learning rate и scheduler, уменьшающий learning rate при выходе val_loss на плато
- Модель получилось обучить с train_loss = 0.056 и val_loss = 0.79 (функция потерь CTC Loss)
- Сделал скрипт `validate.py`, показывающий картинки и предсказания для случайных слов из валидационной части датасета
- Результат можно посмотреть в `src/iam-words-crnn/example/validation.png`
- Бывает, что модель верно распознает даже достаточно неразборчивый почерк
- Попробовал пару слов собственным почерком (`test.py`)
    - Слово "Awesome" распозналось как "Nmesone"
    - Слово "forever" распозналось как "farever", здесь почти точное попадание
- В датасете явно слишком много примеров при слишком малом числе авторов текстов - очень много слов "to" и "of" написанных даже очень неразборчиво распознаются отлично
- Притом слова, написанные разборчиво почти печатными буквами, но собственным почерком, модель распознает не очень хорошо
- Там где модель ошибается, часто буква действительно выглядит двояко и ошибка не совсем рандомная, а вполне предсказуемая 
- Далее будут попытки распознавания целых строк, а затем документов, путем сегментации их на строки
